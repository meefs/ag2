---
sidebarTitle: LLMCondition
title: autogen.agentchat.group.llm_condition.LLMCondition
---
<h2 id="autogen.agentchat.group.llm_condition.LLMCondition" class="doc doc-heading">
    <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>
    <span class="doc doc-object-name doc-class-name">LLMCondition</span>
</h2>

```python
LLMCondition(**data: Any)
```

    Protocol for conditions evaluated by an LLM.<br/>Create a new model by parsing and validating input data from keyword arguments.<br/>Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
    validated to form a valid model.<br/>`self` is explicitly positional-only to allow `self` as a field name.

<b>Parameters:</b>
| Name | Description |
|--|--|
| `**data` | **Type:** Any |

### Class Attributes

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### model_config
<br />

    <br />

### Instance Methods

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### get_prompt

```python
get_prompt(
    self,
    agent: ConversableAgent,
    messages: list[dict[str, Any]]
) -> str
```

    Get the prompt text for LLM evaluation.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `agent` | The agent evaluating the condition<br/><br/>**Type:** ConversableAgent |
| `messages` | The conversation history<br/><br/>**Type:** list[dict[str, typing.Any]] |

<b>Returns:</b>
| Type | Description |
|--|--|
| str | The prompt text to be evaluated by the LLM |

<br />